{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "15mFh6dmZ9tWTnG5c0sZ6jRlg6dRLGOnJ",
     "timestamp": 1677746007368
    }
   ],
   "collapsed_sections": [
    "zvmXvzZ9UKh4"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We beginnen hieronder met het importeren van pandas. Daarnaast veranderen we de instellingen van deze Jupyter Notebook om tabellen makkelijker en overzichterlijker kunnen bekijken."
   ],
   "metadata": {
    "id": "mqcW2poFkIU3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# %reload_ext google.colab.data_table"
   ],
   "metadata": {
    "id": "dxhyiH-ikRh0",
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:13.224748322Z",
     "start_time": "2023-09-15T10:14:13.207017716Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We beginnnen met het inladen van .csv data. Dit doen we met de `read_csv` functie. Aan deze functie geef je de locatie (file path) van het csv bestandje dat je wilt inladen als string. Vervolgens moet je de ingeladen data in een variabele bewaren. In dit geval zullen we deze variabele `df` noemen. Hieronder een demonstratie:\n",
    "\n"
   ],
   "metadata": {
    "id": "P2WjD9kqtTru"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('california_housing_train')"
   ],
   "metadata": {
    "id": "B895GDaHtdfX",
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:14.518699952Z",
     "start_time": "2023-09-15T10:14:14.448554087Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'california_housing_train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcalifornia_housing_train\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/python-workshops/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/python-workshops/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/python-workshops/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/python-workshops/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/python-workshops/lib/python3.10/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'california_housing_train'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Als het goed is, ontvang je een foutmelding omdat het bestand niet gevonden kan worden. In dit geval door een typfout (extensie ontbreekt) en een incorrect opgegeven bestandslocatie (bestand staat in mapje 'data'). Hieronder de verbeterde versie:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/california_housing_train.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:16.765535921Z",
     "start_time": "2023-09-15T10:14:16.670900436Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "De data is ingeladen in een speciaal Pandas object, genaamd een *dataframe*. Dit is grofweg gezegd een tabel met een index, kolommen en bijbehorende kolomwaarden, zoals je misschien gewend bent van programma's als Excel.\n",
    "Laten we bekijken hoe deze data eruit ziet. Dat kan door simpelweg de naam van de dataframe aan te roepen:"
   ],
   "metadata": {
    "id": "EZGxSekIv75t"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "id": "DtxAhpr1xBSv",
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:18.316032570Z",
     "start_time": "2023-09-15T10:14:18.237676632Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0        -114.31     34.19                15.0       5612.0          1283.0   \n1        -114.47     34.40                19.0       7650.0          1901.0   \n2        -114.56     33.69                17.0        720.0           174.0   \n3        -114.57     33.64                14.0       1501.0           337.0   \n4        -114.57     33.57                20.0       1454.0           326.0   \n...          ...       ...                 ...          ...             ...   \n16995    -124.26     40.58                52.0       2217.0           394.0   \n16996    -124.27     40.69                36.0       2349.0           528.0   \n16997    -124.30     41.84                17.0       2677.0           531.0   \n16998    -124.30     41.80                19.0       2672.0           552.0   \n16999    -124.35     40.54                52.0       1820.0           300.0   \n\n       population  households  median_income  median_house_value  \n0          1015.0       472.0         1.4936             66900.0  \n1          1129.0       463.0         1.8200             80100.0  \n2           333.0       117.0         1.6509             85700.0  \n3           515.0       226.0         3.1917             73400.0  \n4           624.0       262.0         1.9250             65500.0  \n...           ...         ...            ...                 ...  \n16995       907.0       369.0         2.3571            111400.0  \n16996      1194.0       465.0         2.5179             79000.0  \n16997      1244.0       456.0         3.0313            103600.0  \n16998      1298.0       478.0         1.9797             85800.0  \n16999       806.0       270.0         3.0147             94600.0  \n\n[17000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-114.31</td>\n      <td>34.19</td>\n      <td>15.0</td>\n      <td>5612.0</td>\n      <td>1283.0</td>\n      <td>1015.0</td>\n      <td>472.0</td>\n      <td>1.4936</td>\n      <td>66900.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-114.47</td>\n      <td>34.40</td>\n      <td>19.0</td>\n      <td>7650.0</td>\n      <td>1901.0</td>\n      <td>1129.0</td>\n      <td>463.0</td>\n      <td>1.8200</td>\n      <td>80100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-114.56</td>\n      <td>33.69</td>\n      <td>17.0</td>\n      <td>720.0</td>\n      <td>174.0</td>\n      <td>333.0</td>\n      <td>117.0</td>\n      <td>1.6509</td>\n      <td>85700.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-114.57</td>\n      <td>33.64</td>\n      <td>14.0</td>\n      <td>1501.0</td>\n      <td>337.0</td>\n      <td>515.0</td>\n      <td>226.0</td>\n      <td>3.1917</td>\n      <td>73400.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-114.57</td>\n      <td>33.57</td>\n      <td>20.0</td>\n      <td>1454.0</td>\n      <td>326.0</td>\n      <td>624.0</td>\n      <td>262.0</td>\n      <td>1.9250</td>\n      <td>65500.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16995</th>\n      <td>-124.26</td>\n      <td>40.58</td>\n      <td>52.0</td>\n      <td>2217.0</td>\n      <td>394.0</td>\n      <td>907.0</td>\n      <td>369.0</td>\n      <td>2.3571</td>\n      <td>111400.0</td>\n    </tr>\n    <tr>\n      <th>16996</th>\n      <td>-124.27</td>\n      <td>40.69</td>\n      <td>36.0</td>\n      <td>2349.0</td>\n      <td>528.0</td>\n      <td>1194.0</td>\n      <td>465.0</td>\n      <td>2.5179</td>\n      <td>79000.0</td>\n    </tr>\n    <tr>\n      <th>16997</th>\n      <td>-124.30</td>\n      <td>41.84</td>\n      <td>17.0</td>\n      <td>2677.0</td>\n      <td>531.0</td>\n      <td>1244.0</td>\n      <td>456.0</td>\n      <td>3.0313</td>\n      <td>103600.0</td>\n    </tr>\n    <tr>\n      <th>16998</th>\n      <td>-124.30</td>\n      <td>41.80</td>\n      <td>19.0</td>\n      <td>2672.0</td>\n      <td>552.0</td>\n      <td>1298.0</td>\n      <td>478.0</td>\n      <td>1.9797</td>\n      <td>85800.0</td>\n    </tr>\n    <tr>\n      <th>16999</th>\n      <td>-124.35</td>\n      <td>40.54</td>\n      <td>52.0</td>\n      <td>1820.0</td>\n      <td>300.0</td>\n      <td>806.0</td>\n      <td>270.0</td>\n      <td>3.0147</td>\n      <td>94600.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17000 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Dataframes opslaan\n",
    "\n",
    "De ingeladen dataframe kunnen we weer opslaan met de commando `df.to_csv`. Let wel op: als de dataframe anders dan `df` heet, gebruik je die naam. Dus als we de dataframe bijvoorbeeld in een variabele genaamd `mijn_data` hadden gestopt, hadden we `mijn_data.to_csv` moeten gebruiken.\n",
    "\n",
    "Vervolgens geef je als argument een string met de locatie waar je de dataframe wilt opslaan, soortgelijk aan de `read_csv` functie eerder.\n",
    "\n",
    "- Uncomment de regels in de codeblock hieronder waar dat gevraagd wordt.\n",
    "- Sla nu in de codeblock hieronder de dataframe `df` op in een zelfgekozen locatie met een zelfgekozen bestandsnaam. \n",
    "- Zoek vervolgens in de Notebook of de csv inderdaad is opgeslagen (klik op het map icoontje in het menu links, onder de vergrootglas). \n",
    "- Probeer daarna weer ditzelfde bestand op te halen.\n",
    "\n"
   ],
   "metadata": {
    "id": "sI7k8aeDOWwC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Opdracht: Dataframes opslaan\n",
    "\n",
    "# Kies een locatie voor de opgeslagen csv\n",
    "# opslag_locatie = <INVULLEN>  # Uncomment deze regel\n",
    "\n",
    "# Sla csv op in gekozen locatie\n",
    "# df.to_csv(<INVULLEN>) # Uncomment deze regel\n",
    "\n",
    "# Haal de opgeslagen csv weer op en sla in een andere dataframe op\n",
    "# df2 = pd.read_csv(<INVULLEN>) # Uncomment deze regel"
   ],
   "metadata": {
    "id": "Q2MJdqwkRQGh",
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:20.960617846Z",
     "start_time": "2023-09-15T10:14:20.936323923Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Dataframes opslaan"
   ],
   "metadata": {
    "id": "WEBNuwTVSQc2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Antwoord: Dataframes opslaan\n",
    "\n",
    "# Kies een locatie voor de opgeslagen csv\n",
    "opslag_locatie = 'data/california_housing_kopie.csv'\n",
    "\n",
    "# Sla csv op in gekozen locatie\n",
    "df.to_csv(opslag_locatie)\n",
    "\n",
    "# Haal de opgeslagen csv weer op en sla in een andere dataframe op\n",
    "df2 = pd.read_csv(opslag_locatie)"
   ],
   "metadata": {
    "cellView": "form",
    "id": "7OIiMg_7SUAP",
    "ExecuteTime": {
     "end_time": "2023-09-15T10:14:22.501718436Z",
     "start_time": "2023-09-15T10:14:22.349193450Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voor het gemak gebruiken we vanaf nu een data set genaamd `exercises` die inbegrepen zit in de module `Seaborn`."
   ],
   "metadata": {
    "id": "fVPpQV17f-Q6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# vaak wordt df(dataframe) als variabelenaam gebruikt\n",
    "df = sns.load_dataset('exercise').drop(columns=['Unnamed: 0'])\n",
    "df"
   ],
   "metadata": {
    "id": "5FSk3MbulfiA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "source": [
    "Het valt misschien inmiddels op dat veel functies en eigenschappen opgehaald worden met een punt en ook dat meerdere functies achter elkaar uitgevoerd kunnen worden,\n",
    "door deze aan elkaar te schrijven,, gescheiden met een punt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We kunnen wat samenvattende statistieken/eigenschappen van deze Dataframe bekijken met de `info` en `describe` functie"
   ],
   "metadata": {
    "id": "nmZkDmmhTmyZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Data type per kolom en aantal geldige rijen:\")\n",
    "df.info()\n",
    "\n",
    "print()\n",
    "print(\"Samenvattende statistieken per kolom:\")\n",
    "df.describe()"
   ],
   "metadata": {
    "id": "t3ZFrOXVT0j-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Samenvattende statistieken\n",
    " Welke kolommen bevat de bovenstaande dataframe volgens de `info` functie? En welke zie je terug in de uitvoer van de `describe` functie? Waar komt dit verschil vandaan, denk je? Hint: wat is de datatype voor elke kolom volgens de `info` functie?\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "zvmXvzZ9UKh4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Samenvattende statistieken"
   ],
   "metadata": {
    "id": "KdJWyQhrciZf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Volgens de info functie bevatten de kolommen diet, time en kind categorische waardes. \n",
    "# Je kan hier geen statistieken over berekenen, omdat het geen getallen zijn."
   ],
   "metadata": {
    "cellView": "form",
    "id": "DPTPublUgrDd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Om de data vervolgens iets dieper te verkennen, bekijken we de eerste rijen van deze data set d.m.v. de `head` functie."
   ],
   "metadata": {
    "id": "SS7TGc-Rg7UC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# De head functie geeft een voorproefje van de data door de eerste rijen te printen. \n",
    "# Je krijgt standaard de eerste 5 rijen te zien, maar je kan aangeven hoeveel rijen \n",
    "# je wilt: df.head(100) geeft de eerste 100 rijen b.v.\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "id": "S_DnuTzeiY7U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Pandas tail functie \n",
    "Op dezelfde manier geeft de `tail` functie de *laatste* rijen van een dataframe. Haal de laatste 10 rijen hiermee op."
   ],
   "metadata": {
    "id": "Uf_ar2x8jPH6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Gebruik tail functie om de laatste rijen van een dataframe op te halen\n",
    "# df.<INVULLEN> # Uncomment deze regel"
   ],
   "metadata": {
    "id": "5VHlGTnKhaWY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Pandas tail functie"
   ],
   "metadata": {
    "id": "yOVozxG9jBr6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Gebruik tail functie om de laatste rijen van een dataframe op te halen\n",
    "df.tail(10)"
   ],
   "metadata": {
    "id": "KprwjmNMlJMB",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Krachtiger is de `loc` functie (locate). Hiermee kunnen we specifieke rijen ophalen. Bijvoorbeeld aan de hand van de index (rijnummer)."
   ],
   "metadata": {
    "id": "LQddKnVLlI2E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Haal index 2 tot en met 4 op\n",
    "df.loc[2:4]"
   ],
   "metadata": {
    "id": "j_Wvq4QRmW3v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Haal van index 2 tot en met 10 elke tweede rij (dus steeds eentje overslaan)\n",
    "df.loc[2:10:2]"
   ],
   "metadata": {
    "id": "xo5XU4hnjbkh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Queryen met index\n",
    "Haal van rijnummer 2 tot en met 10 elke derde rij op (dus steeds twee rijen overslaan)"
   ],
   "metadata": {
    "id": "sWYeOjzCoKwk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# df.loc[<INVULLEN>] # Uncomment deze regel"
   ],
   "metadata": {
    "id": "6uAt_9xHj_hY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Queryen met index"
   ],
   "metadata": {
    "id": "nzZffBURkGlM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "df.loc[2:10:3]"
   ],
   "metadata": {
    "id": "8ShlUwxEoYfB",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Queryen op index is leuk, maar praktischer is om dit op bepaalde kolomwaarden te doen. In Pandas doe je dit meestal in twee stappen. Eerst stel je een query op, waarbij Pandas voor elke rij uitzoekt of deze aan de query voldoet. Pandas geeft hierbij een Series terug met Booleans (True/False). Vervolgens haal je die rijen daadwerkelijk op."
   ],
   "metadata": {
    "id": "ywpSxDjwphjF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# query bevat een tabel met rijnummers en of een rij aan de query voldoet (True of False)\n",
    "query = df['kind'] == 'rest'\n",
    "query"
   ],
   "metadata": {
    "id": "kAveE6YsrLwe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Zoek de rijen op die aan de query voldoen. Dit geeft een Dataframe terug (waarvan je iedere kolom als een Series zou kunnen zien)\n",
    "df_query = df.loc[query]\n",
    "df_query.head()\n"
   ],
   "metadata": {
    "id": "jHjMEpRFrLaM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We beginnen nu met data cleaning. Dit is een overkoepelende term voor het corrigeren van ongewenste of foute data."
   ],
   "metadata": {
    "id": "9wCeKVRY8xrt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sommige data hebben ongeldige waardes. In de Dataframe zie je dan een NaN (Not a Number) en kun je wegfilteren met de `dropna` functie. Wij verwijderen in deze module rijen met NaNs. Maar normaliter, kan je in de praktijk de NaN bijvoorbeeld vervangen met de gemiddelde waarde uit die kolom. Dan hoef je niet de hele rij te verwijderen en dus meer data nuttig gebruiken."
   ],
   "metadata": {
    "id": "lF5hL3a1VSvy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_nan = df.dropna()"
   ],
   "metadata": {
    "id": "TZX58b0GmHOn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We vervolgen de data cleaning door kolommen een betere naam te geven"
   ],
   "metadata": {
    "id": "zkb7oM2lYxx-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We veranderen de kolomnaam 'time' naar 'minutes', aangezien dit niet echt een tijd geeft\n",
    "# maar een aantal minuten\n",
    "df_clean = df_nan.rename(columns={'time': 'minutes'})"
   ],
   "metadata": {
    "id": "VYfHYtVoLoB3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We zien hieronder dat deze kolom strings bevat, maar in dit specifieke geval zouden integers efficienter zijn en ook makkelijker om later te manipuleren/berekeningen op te doen."
   ],
   "metadata": {
    "id": "nvWZ_amaBWUu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# De kolom met aantal minuten bevat tekst/een string:\n",
    "df_clean['minutes'].head()\n"
   ],
   "metadata": {
    "id": "voYOC4DKlvYA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: De apply functie"
   ],
   "metadata": {
    "id": "h5BS6z1OC00T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Om de strings naar integers om te zetten moeten we in de kolomwaardes het gedeelte met getallen behouden en de onnodige 'min' tekst verwijderen.\n",
    "Maak een functie genaamd `verwijder_min` die een string aanneemt en de laatste 4 karakters verwijderd."
   ],
   "metadata": {
    "id": "oPM2mFhneNZk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# def verwijder_min(<INVULLEN>): #Uncomment deze regel\n",
    "    # Verwijder de laatste 4 karakters van de string \n",
    "    # en sla deze op in de variabele 'minuten'\n",
    "    # minuten = <INVULLEN> # Uncomment deze regel\n",
    "#   return <INVULLEN> # Uncomment deze regel"
   ],
   "metadata": {
    "id": "BbPWCck741eA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: De apply functie"
   ],
   "metadata": {
    "id": "y-VS5UO15iSc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "def verwijder_min(tekst): \n",
    "    # Verwijder de laatste 4 karakters van de string \n",
    "    # en sla deze op in de variabele 'minuten'\n",
    "    minuten = tekst[:-4]\n",
    "    return minuten"
   ],
   "metadata": {
    "id": "Vr7M79nkeHlR",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voorheen zagen we dat for loops iteratief elementen uit een lijst kunnen gebruiken/bewerken.\n",
    "In pandas kunnen we soortgelijk een functie toepassen op elke rij door middel van de `apply` functie. We gebruiken nu deze functie om de `verwijder_min` functie op elke rij toe te passen."
   ],
   "metadata": {
    "id": "W5xBYR4get4N"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_clean['minutes_int'] = df_clean['minutes'].apply(verwijder_min)\n",
    "\n",
    "df_clean['minutes_int']"
   ],
   "metadata": {
    "id": "oTK6AjvPea07"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nu we de tekst hebben verwijderd kunnen we aan pandas aangeven dat deze kolom enkel uit integers bestaat. Deze omzetting doe je door de functie `astype` toe te passen met als argument `int`. Pas nu deze omzetting toe."
   ],
   "metadata": {
    "id": "s5kOnZ6NfosQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: String naar integer"
   ],
   "metadata": {
    "id": "KVs4uwHE6fTf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Zet  'minutes' kolom om tot int\n",
    "# df_clean['minutes'] = df_clean['minutes'].astype(<INVULLEN) # Uncomment deze regel\n",
    "\n",
    "# df_clean['minutes'] # Uncomment deze regel"
   ],
   "metadata": {
    "id": "X1TVgaFDhN43"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: String naar integer"
   ],
   "metadata": {
    "id": "pU5C-R0V71gG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Zet 'minutes' kolom om tot int\n",
    "df_clean['minutes_int'] = df_clean['minutes_int'].astype('int')\n",
    "\n",
    "df_clean['minutes_int']"
   ],
   "metadata": {
    "id": "4lQJNDtJfkC0",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nu de data (een beetje) schoon is, kunnen we beginnen met data analyse. Hiervoor gebruiken we hieronder de `groupby`, `pivot_table` en `heatmap` functie.\n",
    "\n"
   ],
   "metadata": {
    "id": "m4Ixi4PW8KIR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Met de 'groupby' functie kan je data groeperen op unieke waardes in een kolom en vervolgens met de 'agg' (aggregatie) functie\n",
    "# statistieken uit halen. Hieronder groeperen we op de twee unieke waardes no fat and low fat uit de kolom diet. Vervolgens berekenen\n",
    "# we de gemiddelde pulse en minutes voor die unieke groepen.\n",
    "df_clean.groupby(by='diet').agg({'pulse': 'mean', 'minutes_int': 'mean'})"
   ],
   "metadata": {
    "id": "PSihJSoEmLkn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# De pivot table functie is uitzonderlijk krachtig om overzichtelijker naar data te kijken\n",
    "df_pivot = pd.pivot_table(df_clean, index='minutes_int', columns='kind', values='pulse')\n",
    "\n",
    "df_pivot"
   ],
   "metadata": {
    "id": "1lws_oOjmBi-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.heatmap(df_pivot, cbar_kws={'label': 'Pulse'})"
   ],
   "metadata": {
    "id": "TWdPZm4c58QB",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nu gaan we een soortgelijke pivot table maken over alle personen (kolom 'id')."
   ],
   "metadata": {
    "id": "3YULufxt7kMN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Query 'running'\n",
    "We beperken ons tot rennen. Selecteer de rijen die hiermee corresponderen.\n"
   ],
   "metadata": {
    "id": "eGmi9Gqd7xc8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Selecteer van de kolom 'kind' alleen de rijen die corresponderen met 'running'\n",
    "# query = df_clean[<INVULLEN>] == <INVULLEN> # Uncomment deze regel\n",
    "# df_clean_running = df_clean[query] # Uncomment deze regel\n",
    "\n",
    "# df_clean_running = df_clean[df_clean['kind'] == 'running']\n"
   ],
   "metadata": {
    "id": "abp0fqPy6viC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Query 'running'"
   ],
   "metadata": {
    "id": "W_HY0SRM-e1L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Selecteer van de kolom 'kind' alleen de rijen die corresponderen met 'running'\n",
    "query = df_clean['kind'] == 'running'\n",
    "df_clean_running = df_clean[query]"
   ],
   "metadata": {
    "cellView": "form",
    "id": "KIdcBeUm-hY2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Pivot IDs\n",
    "Gebruik zoals je hierboven ziet een pivot table om het aantal minuten (kolom *minuten*) en IDs (kolom *id*) als assen (index en columns) te gebruiken met de *pulse* als waarde (values).\n",
    "\n"
   ],
   "metadata": {
    "id": "Ic_pIF-e_Ago"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Pivot table over 'minuten' en 'id' kolom met als waarde 'puls\n",
    "# df_pivot_ids = pd.pivot_table(df_clean_running, index=<INVULLEN>, columns=<INVULLEN>, values=<INVULLEN>) # Uncomment deze regel\n",
    "\n",
    "# Visualiseer pivot table met een heatmap\n",
    "# sns.heatmap(<INVULLEN>) # Uncomment deze regel"
   ],
   "metadata": {
    "id": "J-Eyr9Nw7Iva"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Pivot IDs"
   ],
   "metadata": {
    "id": "Wf97JpU7AaQY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Pivot table over 'minuten' en 'id' kolom met als waarde 'pulse'\n",
    "df_pivot_ids = pd.pivot_table(df_clean_running, index='minutes_int', columns='id', values='pulse')\n",
    "\n",
    "# Visualiseer pivot table met een heatmap\n",
    "sns.heatmap(df_pivot_ids, cbar_kws={'label': 'Pulse'})"
   ],
   "metadata": {
    "id": "CauaKVZEActV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "De `groupby` functie is in veel andere Pandas functies ingebakken, zoals de `hist` functie, waarmee je een histogram kan maken.\n",
    "\n"
   ],
   "metadata": {
    "id": "pooiLFdT1Y9x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_clean['pulse'].hist(by=df_clean['diet']) # Dit plot pulse op x-as"
   ],
   "metadata": {
    "id": "kc2OEyb7z_lS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opdracht: Histogram per activiteit\n",
    "Gebruik zoals hierboven de hist functie om voor elke unieke waarde van de kolom \n",
    "`kind` een histogram van de `pulse` waardes te maken. Wat valt op? Vind je dit logisch?"
   ],
   "metadata": {
    "id": "LYNd_3jwCNUg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Histogram voor elke unieke waarde in de kolom 'kind'\n",
    "# df_clean['pulse'].hist(by=<INVULLEN>) # Uncomment deze regel"
   ],
   "metadata": {
    "id": "_ICVIPk0Ca_u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Antwoord: Histogram per activiteit"
   ],
   "metadata": {
    "id": "DEsT060BCqb9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "# Histogram voor elke unieke waarde in de kolom 'kind'\n",
    "df_clean['pulse'].hist(by=df_clean['kind']) # Dit plot pulse op x-as\n",
    "\n",
    "# Wat valt op? Vind je dit logisch?\n",
    "# Voor de waarde 'rest' komen lagere hartslagen voor dan 'walking' en 'running'\n",
    "# Ik vind dat zelf wel logisch :)"
   ],
   "metadata": {
    "id": "muRk1R7X2mF-",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
